[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "BON in a Box: A tool for monitoring biodiversity",
    "section": "",
    "text": "BON in a Box description.\n\n1 + 1\n\n[1] 2\n\n\nPhoto.\nVideo."
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this site\n\n1 + 1\n\n[1] 2"
  },
  {
    "objectID": "ui/BonInABoxScriptService/docs/InfoReferencesInner.html",
    "href": "ui/BonInABoxScriptService/docs/InfoReferencesInner.html",
    "title": "BonInABoxScriptService.InfoReferencesInner",
    "section": "",
    "text": "Name\nType\nDescription\nNotes\n\n\n\n\ntext\nString\n\n[optional]\n\n\ndoi\nString\n\n[optional]"
  },
  {
    "objectID": "ui/BonInABoxScriptService/docs/InfoReferencesInner.html#properties",
    "href": "ui/BonInABoxScriptService/docs/InfoReferencesInner.html#properties",
    "title": "BonInABoxScriptService.InfoReferencesInner",
    "section": "",
    "text": "Name\nType\nDescription\nNotes\n\n\n\n\ntext\nString\n\n[optional]\n\n\ndoi\nString\n\n[optional]"
  },
  {
    "objectID": "ui/BonInABoxScriptService/docs/InfoOutputsValue.html",
    "href": "ui/BonInABoxScriptService/docs/InfoOutputsValue.html",
    "title": "BonInABoxScriptService.InfoOutputsValue",
    "section": "",
    "text": "Name\nType\nDescription\nNotes\n\n\n\n\ndescription\nString\n\n[optional]\n\n\nlabel\nString\n\n[optional]\n\n\nweight\nNumber\nThe weight is used to sort outputs in the client UI.\n[optional]\n\n\ntype\nString\n\n[optional]\n\n\nrange\n[Number]\n\n[optional]\n\n\noptions\n[String]\n\n[optional]\n\n\nproperties\n[String]\n\n[optional]\n\n\nexample\nInfoOutputsValueExample\n\n[optional]"
  },
  {
    "objectID": "ui/BonInABoxScriptService/docs/InfoOutputsValue.html#properties",
    "href": "ui/BonInABoxScriptService/docs/InfoOutputsValue.html#properties",
    "title": "BonInABoxScriptService.InfoOutputsValue",
    "section": "",
    "text": "Name\nType\nDescription\nNotes\n\n\n\n\ndescription\nString\n\n[optional]\n\n\nlabel\nString\n\n[optional]\n\n\nweight\nNumber\nThe weight is used to sort outputs in the client UI.\n[optional]\n\n\ntype\nString\n\n[optional]\n\n\nrange\n[Number]\n\n[optional]\n\n\noptions\n[String]\n\n[optional]\n\n\nproperties\n[String]\n\n[optional]\n\n\nexample\nInfoOutputsValueExample\n\n[optional]"
  },
  {
    "objectID": "ui/BonInABoxScriptService/docs/InfoInputsValueExample.html",
    "href": "ui/BonInABoxScriptService/docs/InfoInputsValueExample.html",
    "title": "BonInABoxScriptService.InfoInputsValueExample",
    "section": "",
    "text": "Name\nType\nDescription\nNotes"
  },
  {
    "objectID": "ui/BonInABoxScriptService/docs/InfoInputsValueExample.html#properties",
    "href": "ui/BonInABoxScriptService/docs/InfoInputsValueExample.html#properties",
    "title": "BonInABoxScriptService.InfoInputsValueExample",
    "section": "",
    "text": "Name\nType\nDescription\nNotes"
  },
  {
    "objectID": "ui/BonInABoxScriptService/docs/InfoAuthorInner.html",
    "href": "ui/BonInABoxScriptService/docs/InfoAuthorInner.html",
    "title": "BonInABoxScriptService.InfoAuthorInner",
    "section": "",
    "text": "Name\nType\nDescription\nNotes\n\n\n\n\nname\nString\nFull name\n[optional]\n\n\nemail\nString\nEmail of the author\n[optional]\n\n\nidentifier\nString\nFull URL of a unique digital identifier such as an ORCID\n[optional]"
  },
  {
    "objectID": "ui/BonInABoxScriptService/docs/InfoAuthorInner.html#properties",
    "href": "ui/BonInABoxScriptService/docs/InfoAuthorInner.html#properties",
    "title": "BonInABoxScriptService.InfoAuthorInner",
    "section": "",
    "text": "Name\nType\nDescription\nNotes\n\n\n\n\nname\nString\nFull name\n[optional]\n\n\nemail\nString\nEmail of the author\n[optional]\n\n\nidentifier\nString\nFull URL of a unique digital identifier such as an ORCID\n[optional]"
  },
  {
    "objectID": "ui/BonInABoxScriptService/docs/DefaultApi.html",
    "href": "ui/BonInABoxScriptService/docs/DefaultApi.html",
    "title": "BonInABoxScriptService.DefaultApi",
    "section": "",
    "text": "All URIs are relative to http://localhost\n\n\n\nMethod\nHTTP request\nDescription\n\n\n\n\ngetInfo\nGET /{type}/{descriptionPath}/info\nGet metadata about this script or pipeline.\n\n\ngetListOf\nGET /{type}/list\nGet a list of available steps of given type and their names.\n\n\ngetOutputFolders\nGET /{type}/{id}/outputs\nGet the output folders of the scripts composing this pipeline\n\n\ngetPipeline\nGET /pipeline/{descriptionPath}/get\nGet JSON file that describes the pipeline.\n\n\ngetVersions\nGET /api/versions\nReturns the version of system components.\n\n\nrun\nPOST /{type}/{descriptionPath}/run\nRuns the script or pipeline matching `descriptionPath`.\n\n\nsavePipeline\nPOST /pipeline/save/{filename}\nSave a json file to the pipeline folder.\n\n\nstop\nGET /{type}/{id}/stop\nStop the specified pipeline run.\n\n\n\n\n\n\nInfo getInfo(type, descriptionPath)\n\nGet metadata about this script or pipeline.\n\n\nimport BonInABoxScriptService from 'bon_in_a_box_script_service';\n\nlet apiInstance = new BonInABoxScriptService.DefaultApi();\nlet type = \"type_example\"; // String | Script or pipeline\nlet descriptionPath = \"descriptionPath_example\"; // String | Where to find the step. For scripts, paths are relative to the /script folder. For pipelines, paths are relative to the /pipeline folder.\napiInstance.getInfo(type, descriptionPath, (error, data, response) =&gt; {\n  if (error) {\n    console.error(error);\n  } else {\n    console.log('API called successfully. Returned data: ' + data);\n  }\n});\n\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nNotes\n\n\n\n\ntype\nString\nScript or pipeline\n\n\n\ndescriptionPath\nString\nWhere to find the step. For scripts, paths are relative to the /script folder. For pipelines, paths are relative to the /pipeline folder.\n\n\n\n\n\n\n\nInfo\n\n\n\nNo authorization required\n\n\n\n\nContent-Type: Not defined\nAccept: application/json\n\n\n\n\n\n\n{String: String} getListOf(type)\n\nGet a list of available steps of given type and their names.\n\n\nimport BonInABoxScriptService from 'bon_in_a_box_script_service';\n\nlet apiInstance = new BonInABoxScriptService.DefaultApi();\nlet type = \"type_example\"; // String | Script or pipeline\napiInstance.getListOf(type, (error, data, response) =&gt; {\n  if (error) {\n    console.error(error);\n  } else {\n    console.log('API called successfully. Returned data: ' + data);\n  }\n});\n\n\n\n\n\n\nName\nType\nDescription\nNotes\n\n\n\n\ntype\nString\nScript or pipeline\n\n\n\n\n\n\n\n{String: String}\n\n\n\nNo authorization required\n\n\n\n\nContent-Type: Not defined\nAccept: application/json\n\n\n\n\n\n\n{String: String} getOutputFolders(type, id)\n\nGet the output folders of the scripts composing this pipeline\n\n\nimport BonInABoxScriptService from 'bon_in_a_box_script_service';\n\nlet apiInstance = new BonInABoxScriptService.DefaultApi();\nlet type = \"type_example\"; // String | Script or pipeline\nlet id = \"id_example\"; // String | Where to find the pipeline in ./script folder.\napiInstance.getOutputFolders(type, id, (error, data, response) =&gt; {\n  if (error) {\n    console.error(error);\n  } else {\n    console.log('API called successfully. Returned data: ' + data);\n  }\n});\n\n\n\n\n\n\nName\nType\nDescription\nNotes\n\n\n\n\ntype\nString\nScript or pipeline\n\n\n\nid\nString\nWhere to find the pipeline in ./script folder.\n\n\n\n\n\n\n\n{String: String}\n\n\n\nNo authorization required\n\n\n\n\nContent-Type: Not defined\nAccept: application/json\n\n\n\n\n\n\nObject getPipeline(descriptionPath)\n\nGet JSON file that describes the pipeline.\n\n\nimport BonInABoxScriptService from 'bon_in_a_box_script_service';\n\nlet apiInstance = new BonInABoxScriptService.DefaultApi();\nlet descriptionPath = \"descriptionPath_example\"; // String | Where to find the step. For scripts, paths are relative to the /script folder. For pipelines, paths are relative to the /pipeline folder.\napiInstance.getPipeline(descriptionPath, (error, data, response) =&gt; {\n  if (error) {\n    console.error(error);\n  } else {\n    console.log('API called successfully. Returned data: ' + data);\n  }\n});\n\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nNotes\n\n\n\n\ndescriptionPath\nString\nWhere to find the step. For scripts, paths are relative to the /script folder. For pipelines, paths are relative to the /pipeline folder.\n\n\n\n\n\n\n\nObject\n\n\n\nNo authorization required\n\n\n\n\nContent-Type: Not defined\nAccept: application/json\n\n\n\n\n\n\nString getVersions()\n\nReturns the version of system components.\n\n\nimport BonInABoxScriptService from 'bon_in_a_box_script_service';\n\nlet apiInstance = new BonInABoxScriptService.DefaultApi();\napiInstance.getVersions((error, data, response) =&gt; {\n  if (error) {\n    console.error(error);\n  } else {\n    console.log('API called successfully. Returned data: ' + data);\n  }\n});\n\n\n\nThis endpoint does not need any parameter.\n\n\n\nString\n\n\n\nNo authorization required\n\n\n\n\nContent-Type: Not defined\nAccept: text/plain\n\n\n\n\n\n\nString run(type, descriptionPath, opts)\n\nRuns the script or pipeline matching `descriptionPath`.\n\n\nimport BonInABoxScriptService from 'bon_in_a_box_script_service';\n\nlet apiInstance = new BonInABoxScriptService.DefaultApi();\nlet type = \"type_example\"; // String | Script or pipeline\nlet descriptionPath = \"descriptionPath_example\"; // String | Where to find the step. For scripts, paths are relative to the /script folder. For pipelines, paths are relative to the /pipeline folder.\nlet opts = {\n  'body': \"body_example\" // String | Content of input.json for this run\n};\napiInstance.run(type, descriptionPath, opts, (error, data, response) =&gt; {\n  if (error) {\n    console.error(error);\n  } else {\n    console.log('API called successfully. Returned data: ' + data);\n  }\n});\n\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nNotes\n\n\n\n\ntype\nString\nScript or pipeline\n\n\n\ndescriptionPath\nString\nWhere to find the step. For scripts, paths are relative to the /script folder. For pipelines, paths are relative to the /pipeline folder.\n\n\n\nbody\nString\nContent of input.json for this run\n[optional]\n\n\n\n\n\n\nString\n\n\n\nNo authorization required\n\n\n\n\nContent-Type: text/plain\nAccept: text/plain\n\n\n\n\n\n\nString savePipeline(filename, requestBody)\n\nSave a json file to the pipeline folder.\n\n\nimport BonInABoxScriptService from 'bon_in_a_box_script_service';\n\nlet apiInstance = new BonInABoxScriptService.DefaultApi();\nlet filename = \"filename_example\"; // String | The name of the JSON file (without extension).\nlet requestBody = {key: null}; // {String: Object} | Content of pipeline.json to save\napiInstance.savePipeline(filename, requestBody, (error, data, response) =&gt; {\n  if (error) {\n    console.error(error);\n  } else {\n    console.log('API called successfully. Returned data: ' + data);\n  }\n});\n\n\n\n\n\n\nName\nType\nDescription\nNotes\n\n\n\n\nfilename\nString\nThe name of the JSON file (without extension).\n\n\n\nrequestBody\n{String: Object}\nContent of pipeline.json to save\n\n\n\n\n\n\n\nString\n\n\n\nNo authorization required\n\n\n\n\nContent-Type: application/json\nAccept: text/plain\n\n\n\n\n\n\nstop(type, id)\n\nStop the specified pipeline run.\n\n\nimport BonInABoxScriptService from 'bon_in_a_box_script_service';\n\nlet apiInstance = new BonInABoxScriptService.DefaultApi();\nlet type = \"type_example\"; // String | Script or pipeline\nlet id = \"id_example\"; // String | Where to find the pipeline in ./script folder.\napiInstance.stop(type, id, (error, data, response) =&gt; {\n  if (error) {\n    console.error(error);\n  } else {\n    console.log('API called successfully.');\n  }\n});\n\n\n\n\n\n\nName\nType\nDescription\nNotes\n\n\n\n\ntype\nString\nScript or pipeline\n\n\n\nid\nString\nWhere to find the pipeline in ./script folder.\n\n\n\n\n\n\n\nnull (empty response body)\n\n\n\nNo authorization required\n\n\n\n\nContent-Type: Not defined\nAccept: Not defined"
  },
  {
    "objectID": "ui/BonInABoxScriptService/docs/DefaultApi.html#getinfo",
    "href": "ui/BonInABoxScriptService/docs/DefaultApi.html#getinfo",
    "title": "BonInABoxScriptService.DefaultApi",
    "section": "",
    "text": "Info getInfo(type, descriptionPath)\n\nGet metadata about this script or pipeline.\n\n\nimport BonInABoxScriptService from 'bon_in_a_box_script_service';\n\nlet apiInstance = new BonInABoxScriptService.DefaultApi();\nlet type = \"type_example\"; // String | Script or pipeline\nlet descriptionPath = \"descriptionPath_example\"; // String | Where to find the step. For scripts, paths are relative to the /script folder. For pipelines, paths are relative to the /pipeline folder.\napiInstance.getInfo(type, descriptionPath, (error, data, response) =&gt; {\n  if (error) {\n    console.error(error);\n  } else {\n    console.log('API called successfully. Returned data: ' + data);\n  }\n});\n\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nNotes\n\n\n\n\ntype\nString\nScript or pipeline\n\n\n\ndescriptionPath\nString\nWhere to find the step. For scripts, paths are relative to the /script folder. For pipelines, paths are relative to the /pipeline folder.\n\n\n\n\n\n\n\nInfo\n\n\n\nNo authorization required\n\n\n\n\nContent-Type: Not defined\nAccept: application/json"
  },
  {
    "objectID": "ui/BonInABoxScriptService/docs/DefaultApi.html#getlistof",
    "href": "ui/BonInABoxScriptService/docs/DefaultApi.html#getlistof",
    "title": "BonInABoxScriptService.DefaultApi",
    "section": "",
    "text": "{String: String} getListOf(type)\n\nGet a list of available steps of given type and their names.\n\n\nimport BonInABoxScriptService from 'bon_in_a_box_script_service';\n\nlet apiInstance = new BonInABoxScriptService.DefaultApi();\nlet type = \"type_example\"; // String | Script or pipeline\napiInstance.getListOf(type, (error, data, response) =&gt; {\n  if (error) {\n    console.error(error);\n  } else {\n    console.log('API called successfully. Returned data: ' + data);\n  }\n});\n\n\n\n\n\n\nName\nType\nDescription\nNotes\n\n\n\n\ntype\nString\nScript or pipeline\n\n\n\n\n\n\n\n{String: String}\n\n\n\nNo authorization required\n\n\n\n\nContent-Type: Not defined\nAccept: application/json"
  },
  {
    "objectID": "ui/BonInABoxScriptService/docs/DefaultApi.html#getoutputfolders",
    "href": "ui/BonInABoxScriptService/docs/DefaultApi.html#getoutputfolders",
    "title": "BonInABoxScriptService.DefaultApi",
    "section": "",
    "text": "{String: String} getOutputFolders(type, id)\n\nGet the output folders of the scripts composing this pipeline\n\n\nimport BonInABoxScriptService from 'bon_in_a_box_script_service';\n\nlet apiInstance = new BonInABoxScriptService.DefaultApi();\nlet type = \"type_example\"; // String | Script or pipeline\nlet id = \"id_example\"; // String | Where to find the pipeline in ./script folder.\napiInstance.getOutputFolders(type, id, (error, data, response) =&gt; {\n  if (error) {\n    console.error(error);\n  } else {\n    console.log('API called successfully. Returned data: ' + data);\n  }\n});\n\n\n\n\n\n\nName\nType\nDescription\nNotes\n\n\n\n\ntype\nString\nScript or pipeline\n\n\n\nid\nString\nWhere to find the pipeline in ./script folder.\n\n\n\n\n\n\n\n{String: String}\n\n\n\nNo authorization required\n\n\n\n\nContent-Type: Not defined\nAccept: application/json"
  },
  {
    "objectID": "ui/BonInABoxScriptService/docs/DefaultApi.html#getpipeline",
    "href": "ui/BonInABoxScriptService/docs/DefaultApi.html#getpipeline",
    "title": "BonInABoxScriptService.DefaultApi",
    "section": "",
    "text": "Object getPipeline(descriptionPath)\n\nGet JSON file that describes the pipeline.\n\n\nimport BonInABoxScriptService from 'bon_in_a_box_script_service';\n\nlet apiInstance = new BonInABoxScriptService.DefaultApi();\nlet descriptionPath = \"descriptionPath_example\"; // String | Where to find the step. For scripts, paths are relative to the /script folder. For pipelines, paths are relative to the /pipeline folder.\napiInstance.getPipeline(descriptionPath, (error, data, response) =&gt; {\n  if (error) {\n    console.error(error);\n  } else {\n    console.log('API called successfully. Returned data: ' + data);\n  }\n});\n\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nNotes\n\n\n\n\ndescriptionPath\nString\nWhere to find the step. For scripts, paths are relative to the /script folder. For pipelines, paths are relative to the /pipeline folder.\n\n\n\n\n\n\n\nObject\n\n\n\nNo authorization required\n\n\n\n\nContent-Type: Not defined\nAccept: application/json"
  },
  {
    "objectID": "ui/BonInABoxScriptService/docs/DefaultApi.html#getversions",
    "href": "ui/BonInABoxScriptService/docs/DefaultApi.html#getversions",
    "title": "BonInABoxScriptService.DefaultApi",
    "section": "",
    "text": "String getVersions()\n\nReturns the version of system components.\n\n\nimport BonInABoxScriptService from 'bon_in_a_box_script_service';\n\nlet apiInstance = new BonInABoxScriptService.DefaultApi();\napiInstance.getVersions((error, data, response) =&gt; {\n  if (error) {\n    console.error(error);\n  } else {\n    console.log('API called successfully. Returned data: ' + data);\n  }\n});\n\n\n\nThis endpoint does not need any parameter.\n\n\n\nString\n\n\n\nNo authorization required\n\n\n\n\nContent-Type: Not defined\nAccept: text/plain"
  },
  {
    "objectID": "ui/BonInABoxScriptService/docs/DefaultApi.html#run",
    "href": "ui/BonInABoxScriptService/docs/DefaultApi.html#run",
    "title": "BonInABoxScriptService.DefaultApi",
    "section": "",
    "text": "String run(type, descriptionPath, opts)\n\nRuns the script or pipeline matching `descriptionPath`.\n\n\nimport BonInABoxScriptService from 'bon_in_a_box_script_service';\n\nlet apiInstance = new BonInABoxScriptService.DefaultApi();\nlet type = \"type_example\"; // String | Script or pipeline\nlet descriptionPath = \"descriptionPath_example\"; // String | Where to find the step. For scripts, paths are relative to the /script folder. For pipelines, paths are relative to the /pipeline folder.\nlet opts = {\n  'body': \"body_example\" // String | Content of input.json for this run\n};\napiInstance.run(type, descriptionPath, opts, (error, data, response) =&gt; {\n  if (error) {\n    console.error(error);\n  } else {\n    console.log('API called successfully. Returned data: ' + data);\n  }\n});\n\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nNotes\n\n\n\n\ntype\nString\nScript or pipeline\n\n\n\ndescriptionPath\nString\nWhere to find the step. For scripts, paths are relative to the /script folder. For pipelines, paths are relative to the /pipeline folder.\n\n\n\nbody\nString\nContent of input.json for this run\n[optional]\n\n\n\n\n\n\nString\n\n\n\nNo authorization required\n\n\n\n\nContent-Type: text/plain\nAccept: text/plain"
  },
  {
    "objectID": "ui/BonInABoxScriptService/docs/DefaultApi.html#savepipeline",
    "href": "ui/BonInABoxScriptService/docs/DefaultApi.html#savepipeline",
    "title": "BonInABoxScriptService.DefaultApi",
    "section": "",
    "text": "String savePipeline(filename, requestBody)\n\nSave a json file to the pipeline folder.\n\n\nimport BonInABoxScriptService from 'bon_in_a_box_script_service';\n\nlet apiInstance = new BonInABoxScriptService.DefaultApi();\nlet filename = \"filename_example\"; // String | The name of the JSON file (without extension).\nlet requestBody = {key: null}; // {String: Object} | Content of pipeline.json to save\napiInstance.savePipeline(filename, requestBody, (error, data, response) =&gt; {\n  if (error) {\n    console.error(error);\n  } else {\n    console.log('API called successfully. Returned data: ' + data);\n  }\n});\n\n\n\n\n\n\nName\nType\nDescription\nNotes\n\n\n\n\nfilename\nString\nThe name of the JSON file (without extension).\n\n\n\nrequestBody\n{String: Object}\nContent of pipeline.json to save\n\n\n\n\n\n\n\nString\n\n\n\nNo authorization required\n\n\n\n\nContent-Type: application/json\nAccept: text/plain"
  },
  {
    "objectID": "ui/BonInABoxScriptService/docs/DefaultApi.html#stop",
    "href": "ui/BonInABoxScriptService/docs/DefaultApi.html#stop",
    "title": "BonInABoxScriptService.DefaultApi",
    "section": "",
    "text": "stop(type, id)\n\nStop the specified pipeline run.\n\n\nimport BonInABoxScriptService from 'bon_in_a_box_script_service';\n\nlet apiInstance = new BonInABoxScriptService.DefaultApi();\nlet type = \"type_example\"; // String | Script or pipeline\nlet id = \"id_example\"; // String | Where to find the pipeline in ./script folder.\napiInstance.stop(type, id, (error, data, response) =&gt; {\n  if (error) {\n    console.error(error);\n  } else {\n    console.log('API called successfully.');\n  }\n});\n\n\n\n\n\n\nName\nType\nDescription\nNotes\n\n\n\n\ntype\nString\nScript or pipeline\n\n\n\nid\nString\nWhere to find the pipeline in ./script folder.\n\n\n\n\n\n\n\nnull (empty response body)\n\n\n\nNo authorization required\n\n\n\n\nContent-Type: Not defined\nAccept: Not defined"
  },
  {
    "objectID": "README-dev.html",
    "href": "README-dev.html",
    "title": "Developer documentation",
    "section": "",
    "text": "If you wish to contribute code to this pipeline engine, please let us know at web@geobon.org.\nThe recommended method is to setup an instance of BON in a Box somewhere you can easily play with the script files, using the local or remote setup in the user documentation. You can create a branch or fork to save your work. Once complete, open a pull request to this repository. The pull request will be peer-reviewed before acceptation.\n\n\n\nThe code in this repository runs an engine, but the engine needs content! Here are the steps to start the server in development mode with the BON in a Box scripts and pipelines:\n\ndocker and docker compose must be installed.\nClone this repo: git clone git@github.com:GEO-BON/bon-in-a-box-pipeline-engine.git pipeline-engine\ncd pipeline-engine\nClone the BON in a Box repo (or any compatible repo of your choice) into the pipeline-repo folder: git clone git@github.com:GEO-BON/bon-in-a-box-pipelines.git pipeline-repo\nCreate a runner.env file as per user instructions.\ncd ..\nPull the pre-compiled images: ./dev-server.sh pull\n\n\n\n\nFor the global project, Visual Studio Code. Recommended extensions:\n\nGitLens\nMarkdown Preview Mermaid\nMermaid Markdown Syntax Highlighting\n\nFor the script-server (Kotlin code), IntelliJ Idea. Note that on Linux there will be an ownership conflict between gradle files generated by the development docker and those from the IDE. To solve this, make sure to stop the dockers and run sudo chown -R &lt;yourinfo&gt;:&lt;yourinfo&gt; . before running the tests in IntelliJ.\n\n\n\n\nBuild the remaining images: ./dev-server.sh build\nStart the development server: ./dev-server.sh up\n\nIf there is a container name conflict, run ./dev-server.sh clean\n\n\nThis command enables:\n\nOpenAPI editor at http://localhost/swagger/\nUI server: React automatic hot-swapping\nScript-server: Kotlin hot-swapping by launching ./script-server/hotswap.sh\nNGINX: http-proxy/conf.d/ngnix.conf will be loaded\n\nOnce in a while you should use docker compose -f compose.yml -f compose.dev.yml pull to have the latest base images.\n\n\n\nstateDiagram-v2\n    state \"script-server\" as script\n    state \"scripts (static)\" as scripts\n    state \"output (static)\" as output\n    state \"R runner\" as r\n    state \"Julia runner\" as julia\n\n    [*] --&gt; ngnix\n    ngnix --&gt; ui\n    ngnix --&gt; script\n    ngnix --&gt; output\n    script --&gt; scripts\n    script --&gt; r\n    script --&gt; julia\n\nui: React front-end\nscript-server: Running scripts and pipeline orchestration\nR runner: Docker dedicated to runs R code, with most relevant packages pre-installed\nJulia runner: Docker dedicated to runs Julia code\n\nIn addition to these services,\n\nscripts folder contains all the scripts that can be run.\noutput folder contains all scripts result.\n\n\n\n\nflowchart TD\n never[Never ran] --&gt; running[Running]\n running --&gt; input[(- run folder\\n- input.json)]\n running --&gt; log[(log file)]\n running --&gt; success{Success?}\n success --&gt; |Yes| Done\n Done --&gt; output[(output.json)]\n success --&gt; |No| Failed\n Failed --&gt; |Add error flag|output\n\n\n\nThe OpenApi specification file is used by the UI to launch runs and track them until completion.\n\n\nsequenceDiagram\n    ui-&gt;&gt;script_server: script/list\n    script_server--&gt;&gt;ui:\n\n    ui-&gt;&gt;script_server: script/info\n    script_server--&gt;&gt;ui:\n\n    ui-&gt;&gt;script_server: script/run\n    script_server-&gt;&gt;script: launch\n    script_server--&gt;&gt;ui: runId\n\n    loop Until output.json file generated\n        ui-&gt;&gt;script_server: output/{id}/logs.txt\n        script_server--&gt;&gt;ui:\n\n        ui-&gt;&gt;script_server: output/{id}/output.json\n    end\n\n\n    script--&gt;&gt;script_server: output.json\n\n    ui-&gt;&gt;script_server: output/{id}/output.json\n    script_server--&gt;&gt;ui:\n\n\n\n\nsequenceDiagram\n    ui-&gt;&gt;script_server: pipeline/list\n    script_server--&gt;&gt;ui:\n\n    ui-&gt;&gt;script_server: pipeline/&lt;path&gt;/info\n    script_server--&gt;&gt;ui:\n\n    ui-&gt;&gt;script_server: pipeline/&lt;path&gt;/run\n    script_server--&gt;&gt;ui: id\n    loop For each step\n        script_server-&gt;&gt;script: run\n        Note right of script: see previous diagram\n        script--&gt;&gt;script_server: output.json (script)\n        ui-&gt;&gt;script_server: pipeline/&lt;id&gt;/outputs\n        script_server--&gt;&gt;ui: pipelineOutput.json (pipeline)\n    end\n\nEvery second, the UI polls for:\n\npipelineOutput.json from the pipeline, to get the output folders of individual scripts. Stops polling when pipeline stops.\nlogs.txt of individual scripts, for realtime logging, only if log section is opened. Stops when individual script completes, or when log section closed.\noutput.json of individual scripts, to know when script completes and display its outputs. Stops when script stops.\n\n\n\n\n\nUsing http://localhost/swagger, edit the specification.\nCopy the result to script-server/api/openapi.yaml\nUse ui/BonInABoxScriptService/generate-client.sh and script-server/generate-server-openapitools.sh to regenerate the client and the server.\nMerge carefully, not all generated code is to be kept.\nImplement the gaps.\n\n\n\n\n\nSince runner-r and runner-julia run in a separate docker, when the user stops the pipeline, the signal must go from the script-server, to the runner, to the running script. Docker does not allow this by default, this is why we save the PID in a file and use a separate exec command to kill the process.\nThe PID file is called .pid and is located in the output folder of the run. It is deleted when the script completes. For details, see ScriptRun.kt."
  },
  {
    "objectID": "README-dev.html#contributing",
    "href": "README-dev.html#contributing",
    "title": "Developer documentation",
    "section": "",
    "text": "If you wish to contribute code to this pipeline engine, please let us know at web@geobon.org.\nThe recommended method is to setup an instance of BON in a Box somewhere you can easily play with the script files, using the local or remote setup in the user documentation. You can create a branch or fork to save your work. Once complete, open a pull request to this repository. The pull request will be peer-reviewed before acceptation."
  },
  {
    "objectID": "README-dev.html#getting-the-code",
    "href": "README-dev.html#getting-the-code",
    "title": "Developer documentation",
    "section": "",
    "text": "The code in this repository runs an engine, but the engine needs content! Here are the steps to start the server in development mode with the BON in a Box scripts and pipelines:\n\ndocker and docker compose must be installed.\nClone this repo: git clone git@github.com:GEO-BON/bon-in-a-box-pipeline-engine.git pipeline-engine\ncd pipeline-engine\nClone the BON in a Box repo (or any compatible repo of your choice) into the pipeline-repo folder: git clone git@github.com:GEO-BON/bon-in-a-box-pipelines.git pipeline-repo\nCreate a runner.env file as per user instructions.\ncd ..\nPull the pre-compiled images: ./dev-server.sh pull"
  },
  {
    "objectID": "README-dev.html#ide-setup",
    "href": "README-dev.html#ide-setup",
    "title": "Developer documentation",
    "section": "",
    "text": "For the global project, Visual Studio Code. Recommended extensions:\n\nGitLens\nMarkdown Preview Mermaid\nMermaid Markdown Syntax Highlighting\n\nFor the script-server (Kotlin code), IntelliJ Idea. Note that on Linux there will be an ownership conflict between gradle files generated by the development docker and those from the IDE. To solve this, make sure to stop the dockers and run sudo chown -R &lt;yourinfo&gt;:&lt;yourinfo&gt; . before running the tests in IntelliJ."
  },
  {
    "objectID": "README-dev.html#launching-the-dockers-in-development-mode",
    "href": "README-dev.html#launching-the-dockers-in-development-mode",
    "title": "Developer documentation",
    "section": "",
    "text": "Build the remaining images: ./dev-server.sh build\nStart the development server: ./dev-server.sh up\n\nIf there is a container name conflict, run ./dev-server.sh clean\n\n\nThis command enables:\n\nOpenAPI editor at http://localhost/swagger/\nUI server: React automatic hot-swapping\nScript-server: Kotlin hot-swapping by launching ./script-server/hotswap.sh\nNGINX: http-proxy/conf.d/ngnix.conf will be loaded\n\nOnce in a while you should use docker compose -f compose.yml -f compose.dev.yml pull to have the latest base images."
  },
  {
    "objectID": "README-dev.html#microservice-infrastructure",
    "href": "README-dev.html#microservice-infrastructure",
    "title": "Developer documentation",
    "section": "",
    "text": "stateDiagram-v2\n    state \"script-server\" as script\n    state \"scripts (static)\" as scripts\n    state \"output (static)\" as output\n    state \"R runner\" as r\n    state \"Julia runner\" as julia\n\n    [*] --&gt; ngnix\n    ngnix --&gt; ui\n    ngnix --&gt; script\n    ngnix --&gt; output\n    script --&gt; scripts\n    script --&gt; r\n    script --&gt; julia\n\nui: React front-end\nscript-server: Running scripts and pipeline orchestration\nR runner: Docker dedicated to runs R code, with most relevant packages pre-installed\nJulia runner: Docker dedicated to runs Julia code\n\nIn addition to these services,\n\nscripts folder contains all the scripts that can be run.\noutput folder contains all scripts result."
  },
  {
    "objectID": "README-dev.html#script-lifecycle-artifacts",
    "href": "README-dev.html#script-lifecycle-artifacts",
    "title": "Developer documentation",
    "section": "",
    "text": "flowchart TD\n never[Never ran] --&gt; running[Running]\n running --&gt; input[(- run folder\\n- input.json)]\n running --&gt; log[(log file)]\n running --&gt; success{Success?}\n success --&gt; |Yes| Done\n Done --&gt; output[(output.json)]\n success --&gt; |No| Failed\n Failed --&gt; |Add error flag|output"
  },
  {
    "objectID": "README-dev.html#openapi-specification",
    "href": "README-dev.html#openapi-specification",
    "title": "Developer documentation",
    "section": "",
    "text": "The OpenApi specification file is used by the UI to launch runs and track them until completion.\n\n\nsequenceDiagram\n    ui-&gt;&gt;script_server: script/list\n    script_server--&gt;&gt;ui:\n\n    ui-&gt;&gt;script_server: script/info\n    script_server--&gt;&gt;ui:\n\n    ui-&gt;&gt;script_server: script/run\n    script_server-&gt;&gt;script: launch\n    script_server--&gt;&gt;ui: runId\n\n    loop Until output.json file generated\n        ui-&gt;&gt;script_server: output/{id}/logs.txt\n        script_server--&gt;&gt;ui:\n\n        ui-&gt;&gt;script_server: output/{id}/output.json\n    end\n\n\n    script--&gt;&gt;script_server: output.json\n\n    ui-&gt;&gt;script_server: output/{id}/output.json\n    script_server--&gt;&gt;ui:\n\n\n\n\nsequenceDiagram\n    ui-&gt;&gt;script_server: pipeline/list\n    script_server--&gt;&gt;ui:\n\n    ui-&gt;&gt;script_server: pipeline/&lt;path&gt;/info\n    script_server--&gt;&gt;ui:\n\n    ui-&gt;&gt;script_server: pipeline/&lt;path&gt;/run\n    script_server--&gt;&gt;ui: id\n    loop For each step\n        script_server-&gt;&gt;script: run\n        Note right of script: see previous diagram\n        script--&gt;&gt;script_server: output.json (script)\n        ui-&gt;&gt;script_server: pipeline/&lt;id&gt;/outputs\n        script_server--&gt;&gt;ui: pipelineOutput.json (pipeline)\n    end\n\nEvery second, the UI polls for:\n\npipelineOutput.json from the pipeline, to get the output folders of individual scripts. Stops polling when pipeline stops.\nlogs.txt of individual scripts, for realtime logging, only if log section is opened. Stops when individual script completes, or when log section closed.\noutput.json of individual scripts, to know when script completes and display its outputs. Stops when script stops.\n\n\n\n\n\nUsing http://localhost/swagger, edit the specification.\nCopy the result to script-server/api/openapi.yaml\nUse ui/BonInABoxScriptService/generate-client.sh and script-server/generate-server-openapitools.sh to regenerate the client and the server.\nMerge carefully, not all generated code is to be kept.\nImplement the gaps."
  },
  {
    "objectID": "README-dev.html#debugging-signal-forwarding",
    "href": "README-dev.html#debugging-signal-forwarding",
    "title": "Developer documentation",
    "section": "",
    "text": "Since runner-r and runner-julia run in a separate docker, when the user stops the pipeline, the signal must go from the script-server, to the runner, to the running script. Docker does not allow this by default, this is why we save the PID in a file and use a separate exec command to kill the process.\nThe PID file is called .pid and is located in the output folder of the run. It is deleted when the script completes. For details, see ScriptRun.kt."
  },
  {
    "objectID": "README-user.html",
    "href": "README-user.html",
    "title": "BON in a Box Pipelines - User Documentation",
    "section": "",
    "text": "If you wish to contribute your indicator or EBV code, please let us know at web@geobon.org.\nThe recommended method is to setup an instance of BON in a Box somewhere you can easily play with the script files, using the local or remote setup below. You can create a branch or fork to save your work. Make sure that the code is general, and will work when used with various parameters, such as in different regions around the globe. Once the integration of the new scripts or pipelines are complete, open a pull request to this repository. The pull request will be peer-reviewed before acceptation.\n\n\n\nPrerequisites : - Git - A github account, with an SSH key registered. See Adding a new SSH key to your GitHub account. - At least 6 GB of free space (this includes the installation of Docker Desktop) - RAM requirements will depend on the scripts that you run. - Windows: - Docker Desktop - Note that it is not necessary to make an account - A Linux shell (git bash, Bash through PowerShell, cygwin, etc.) necessary to run th .sh scripts in the instructions below. - Mac: Docker Desktop - Note that it is not necessary to make an account - Make sure docker is added to the path of your terminal. From a terminal, run command docker run hello-world. If there is an error message, see https://stackoverflow.com/a/71923962/3519951. - If you encounter error no matching manifest for linux/arm64/v8 in the manifest list entries, export DOCKER_DEFAULT_PLATFORM. See https://stackoverflow.com/a/76404045/3519951. - Linux: Docker with Docker Compose installed. It is recommended to add your user to the docker group.\nTo run: 1. Clone repository (Windows users: do not clone the repo in a folder under OneDrive.) This can be done in terminal using the following code: git clone git@github.com:GEO-BON/bon-in-a-box-pipelines.git or in GitHub desktop. 2. Provide the environment variables: - Open the newly cloned repository on your computer - Find the file called runner-sample.env - Duplicate the file and rename the copy to runner.env. - Fill the properties depending on what you intend to run. - Adjust any server option as you see fit. 3. Using a linux terminal (terminal on Mac or Git Bash), navigate to top-level folder. 4. In the linux terminal, type ./server-up.sh - Make sure you have docker open and running on your computer. - The first execution will be long, in order to download the micro-services. The next ones will be shorter or immediate, depending on the changes. - Network problems may cause the process to fail. First try running the command again. Intermediate states are saved so not everything will be redone even when there is a failure. - Windows users may need to turn on virtualization and other tools for Docker Desktop to work and update wsl (“wsl –update”, see https://docs.docker.com/desktop/troubleshoot/topics/#virtualization. Access to the BIOS may be required to enable virtualization) 5. In browser: - http://localhost/ shows the UI 6. ./server-down.sh (to stop the server when done) 7. On Windows, to completely stop the processes, you might have to run wsl --shutdown\nWhen modifying scripts in the /scripts folder, servers do not need to be restarted: - When modifying an existing script, simply re-run the script from the UI and the new version will be executed. - When adding or renaming scripts, refresh the browser page.\nWhen modifying pipelines in the /pipelines folder, servers do not need to be restarted: - In the pipeline editor, click save, paste the file to your file in the pipeline folder and run it from the “pipeline run” page. - When adding or renaming pipelines, refresh the browser page.\n\n\n\nUse the ansible playbook instructions.\n\n\n\nYou have an instance of BON in a Box running, either locally or remotely, and you want to run your first script or pipeline.\nThere is one page to run scripts, and one to run pipelines. Select the script or pipelines from the dropdown and fill the form.\nThe form might ask you for a file. In order to provide a file that you own locally, upload or copy it to the userdata folder. You can then refer to it with a url as such: /userdata/myFile.shp, or /userdata/myFolder/myFile.shp if there are subfolders.\n\n\n\nThe scripts perform the actual work behind the scenes. They are located in /scripts folder\nCurrently supported : - R v4.3.1 - Julia v1.9.3 - Python3 v3.9.2 - sh\nScript lifecycle: 1. Script launched with output folder as a parameter. (In R, an outputFolder variable in the R session. In Julia, Shell and Python, the output folder is received as an argument.) 3. Script reads input.json to get execution parameters (ex. species, area, data source, etc.) 4. Script performs its task 5. Script generates output.json containing links to result files, or native values (number, string, etc.)\nSee empty R script for a minimal script lifecycle example.\n\n\nThe script description is in a .yml file next to the script. It is necessary for the script to be found and connected to other scripts in a pipeline.\nHere is an empty commented sample:\nscript: # script file with extension, such as \"myScript.py\".\nname: # short name, such as My Script\ndescription: # Targetted to those who will interpret pipeline results and edit pipelines.\nauthor: # 1 to many\n  - name: # Full name\n    email: # Optional, email address of the author. This will be publicly available.\n    identifier: # Optional, full URL of a unique digital identifier, such as an ORCID.\nlicense: # Optional. If unspecified, the project's MIT license will apply.\nexternal_link: # Optional, link to a separate project, github repo, etc.\ntimeout: # Optional, in minutes. By defaults steps time out after 1h to avoid hung process to consume resources. It can be made longer for heavy processes.\n\ninputs: # 0 to many\n  key: # replace the word \"key\" by a snake case identifier for this input\n    label: # Human-readable version of the name\n    description: # Targetted to those who will interpret pipeline results and edit pipelines.\n    type: # see below\n    example: # will also be used as default value, can be null\n\noutputs: # 1 to many\n  key:\n    label:\n    description:\n    type:\n    example: # optional, for documentation purpose only\n\nreferences: # 0 to many\n  - text: # plain text reference\n    doi: # link\nSee example\n\n\nEach input and output must declare a type, in lowercase. It can be a primitive or a file.\nThe following primitive types are accepted: | “type” attribute in the yaml | UI rendering | |——————————–|——————————| | boolean | Plain text | | float, float[] | Plain text | | int, int[] | Plain text | | options 2 | Plain text | | text, text[] | Plain text | | (any unknown type) | Plain text |\nAny MIME type is accepted. Here are a few common ones: | File type | MIME type to use in the yaml | UI rendering | | —————————- |——————————- |——————————| | CSV | text/csv | HTML table (partial content) | | GeoJSON | application/geo+json | Map | | GeoPackage | application/geopackage+sqlite3 | Link | | GeoTIFF 1 | image/tiff;application=geotiff | Map widget (leaflet) | | JPG | image/jpg | &lt;img&gt; tag | | Shapefile | application/dbf | Link | | Text | text/plain | Plain text | | TSV | text/tab-separated-values | HTML table (partial content) | | | (any unknown type) | Plain text or link |\nSearch the web to find the appropriate MIME type for your content. Here are a few references: - http://www.iana.org/assignments/media-types/media-types.xhtml - http://svn.apache.org/viewvc/httpd/httpd/trunk/docs/conf/mime.types?view=markup\n1 When used as an output, image/tiff;application=geotiff type allows an additionnal range attribute to be added with the min and max values that the tiff should hold. This will be used for display purposes.\nmap:\n  label: My map\n  description: Some map that shows bla bla...\n  type: image/tiff;application=geotiff\n  range: [0.1, 254]\n  example: https://example.com/mytiff.tif\n2 options type requires an additionnal options attribute to be added with the available options.\noptions_example:\n  label: Options example\n  description: The user has to select between a fixed number of text options. Also called select or enum. The script receives the selected option as text.\n  type: options\n  options:\n    - first option\n    - second option\n    - third option\n  example: third option\n\n\n\n\nThe syntax and structure of the script description file will be validated on push. To run the validation locally, run validate.sh\nThis validates that the syntax and structure are correct, but not that it’s content is correct. Hence, peer review of the scripts and the description files is mandatory before accepting a pull requests.\n\n\n\nThe output keys info, warning and error can be used to report problems in script execution. They do not need to be described in the outputs section of the description. They will be displayed specially in the UI.\nAny error message will halt the rest of the pipeline.\n\n\n\nScripts can install their own dependencies directly (install.packages in R, Pkg.add in Julia, etc). However, it will need to be reinstalled if the server is deployed on another computer or server.\nTo pre-compile the dependency in the image, add it to runners/r-dockerfile or runners/julia-dockerfile. When the pull request is merged to main, a new image will be available to docker compose pull with the added dependencies.\n\n\n\nWhen running a script, a folder is created for each given set of parameters. The same parameters result in the same folder, different parameters result in a different folder. The inputs for a given script are saved in an input.json file in this unique run folder.\nThe file contains the id of the parameters that were specified in the yaml script description, associated to the values for this run. Example:\n{\n    \"fc\": [\"L\", \"LQ\", \"LQHP\"],\n    \"method_select_params\": \"AUC\",\n    \"n_folds\": 2,\n    \"orientation_block\": \"lat_lon\",\n    \"partition_type\": \"block\",\n    \"predictors\": [\n        \"/output/data/loadFromStac/6af2ccfcd4b0ffe243ff01e3b7eccdc3/bio1_75548ca61981-01-01.tif\",\n        \"/output/data/loadFromStac/6af2ccfcd4b0ffe243ff01e3b7eccdc3/bio2_7333b3d111981-01-01.tif\"\n    ],\n    \"presence_background\": \"/output/SDM/setupDataSdm/edb9492031df9e063a5ec5c325bacdb1/presence_background.tsv\",\n    \"proj\": \"EPSG:6623\",\n    \"rm\": [0.5, 1.0, 2.0]\n}\nThe script reads and uses inputs from the input.json file. Example in R:\n## Receiving arguments from input.json.\n## outputFolder is already defined by server\nlibrary(\"rjson\")\ninput &lt;- fromJSON(file=file.path(outputFolder, \"input.json\"))\n\n## Can now be accessed from the map\nprint(input$predictors)\nThe script should perform appropriate parameter validation.\nNote that the inputs will be null if the user left the text box empty.\n\n\n\nThe output files generated by the script must be saved in the run folder. The script must also generate an output.json file in the same folder, that contains a map associating the output ids to their values. Example:\n{\n  \"sdm_pred\": \"/output/SDM/runMaxent/b5937ba69418b65cae7c6cfcfa78b5e8/sdm_pred.tif\",\n  \"sdm_runs\":[\n    \"/output/SDM/runMaxent/b5937ba69418b65cae7c6cfcfa78b5e8/sdm_runs_1.tif\",\n    \"/output/SDM/runMaxent/b5937ba69418b65cae7c6cfcfa78b5e8/sdm_runs_2.tif\"\n  ]\n}\n\n\n\n\nA pipeline is a collection of steps to acheive the desired processing. Each script becomes a pipeline step. \nPipelines also have inputs and outputs. In order to run, a pipeline needs to specify at least one output (rightmost red box in image above). Pipeline IO supports the same types and UI rendering as individual steps, since its inputs are directly fed to the steps, and outputs come from the step outputs.\nFor a general description of pipelines in software engineering, see Wikipedia.\n\n\nThe pipeline editor allows you to create pipelines by plugging steps together.\nThe left pane shows the available steps, the main section shows the canvas.\nOn the right side, a collapsible pane allows to edit the labels and descriptions of the pipeline inputs and outputs.\nTo add a step: drag and drop from the left pane to the canvas. Steps that are single scripts will display with a single border, while steps that are pipelines will display with a double border.\n\n\n\nimage\n\n\nTo connect steps: drag to connect an output and an input handle. Input handles are on the left, output handles are on the right.\nTo add a constant value: double-click on any input to add a constant value linked to this input. It is pre-filled with the example value.\nTo add an output: double-click on any step output to add a pipeline output linked to it, or drag and drop the red box from the left pane and link it manually.\nTo delete a step or a pipe: select it and press the Delete key on your keyboard.\nTo make an array out of single value outputs: if many outputs of the same type are connected to the same input, it will be received as an array by the script.\n\nA single value can also be combined with an array of the same type, to produce a single array.\n\nUser inputs: To provide inputs at runtime, simply leave them unconnected in the pipeline editor. They will be added to the sample input file when running the pipeline.\nIf an input is common to many step, a special user input node can be added to avoid duplication. First, link your nodes to a constant.\n\nThen, use the down arrow to pop the node’s menu. Choose “Convert to user input”.\n\nThe node will change as below, and the details will appear on the right pane, along with the other user inputs.\n\n\n\n\nAny input with no constant value assigned will be considered a pipeline input and user will have to fill the value.\nAdd an output node linked to a step output to specify that this output is an output of the pipeline. All other unmarked step outputs will still be available as intermediate results in the UI.\n\n\n\nimage\n\n\nPipeline inputs and outputs then appear in a collapsible pane on the right of the canvas, where their descriptions and labels can be edited.\n\nOnce edited, make sure to save your work before leaving the page.\n\n\n\nThe editor supports saving and loading on the server, unless explicitly disabled by host. This is done intuitively via the “Load from server” and “Save” buttons.\nIn the event that saving has been disabled on your server instance, the save button will display “Save to clipboard”. To save your modifications: 1. Click save: the content is copied to your clipboard. 2. Make sure you are up to date (e.g. git pull --rebase). 3. Remove all the content of the target file. 4. Paste content and save. 5. Commit and push on a branch using git. 6. To share your modifications, create a pull request for that branch through the github UI."
  },
  {
    "objectID": "README-user.html#contributing",
    "href": "README-user.html#contributing",
    "title": "BON in a Box Pipelines - User Documentation",
    "section": "",
    "text": "If you wish to contribute your indicator or EBV code, please let us know at web@geobon.org.\nThe recommended method is to setup an instance of BON in a Box somewhere you can easily play with the script files, using the local or remote setup below. You can create a branch or fork to save your work. Make sure that the code is general, and will work when used with various parameters, such as in different regions around the globe. Once the integration of the new scripts or pipelines are complete, open a pull request to this repository. The pull request will be peer-reviewed before acceptation."
  },
  {
    "objectID": "README-user.html#running-the-servers-locally",
    "href": "README-user.html#running-the-servers-locally",
    "title": "BON in a Box Pipelines - User Documentation",
    "section": "",
    "text": "Prerequisites : - Git - A github account, with an SSH key registered. See Adding a new SSH key to your GitHub account. - At least 6 GB of free space (this includes the installation of Docker Desktop) - RAM requirements will depend on the scripts that you run. - Windows: - Docker Desktop - Note that it is not necessary to make an account - A Linux shell (git bash, Bash through PowerShell, cygwin, etc.) necessary to run th .sh scripts in the instructions below. - Mac: Docker Desktop - Note that it is not necessary to make an account - Make sure docker is added to the path of your terminal. From a terminal, run command docker run hello-world. If there is an error message, see https://stackoverflow.com/a/71923962/3519951. - If you encounter error no matching manifest for linux/arm64/v8 in the manifest list entries, export DOCKER_DEFAULT_PLATFORM. See https://stackoverflow.com/a/76404045/3519951. - Linux: Docker with Docker Compose installed. It is recommended to add your user to the docker group.\nTo run: 1. Clone repository (Windows users: do not clone the repo in a folder under OneDrive.) This can be done in terminal using the following code: git clone git@github.com:GEO-BON/bon-in-a-box-pipelines.git or in GitHub desktop. 2. Provide the environment variables: - Open the newly cloned repository on your computer - Find the file called runner-sample.env - Duplicate the file and rename the copy to runner.env. - Fill the properties depending on what you intend to run. - Adjust any server option as you see fit. 3. Using a linux terminal (terminal on Mac or Git Bash), navigate to top-level folder. 4. In the linux terminal, type ./server-up.sh - Make sure you have docker open and running on your computer. - The first execution will be long, in order to download the micro-services. The next ones will be shorter or immediate, depending on the changes. - Network problems may cause the process to fail. First try running the command again. Intermediate states are saved so not everything will be redone even when there is a failure. - Windows users may need to turn on virtualization and other tools for Docker Desktop to work and update wsl (“wsl –update”, see https://docs.docker.com/desktop/troubleshoot/topics/#virtualization. Access to the BIOS may be required to enable virtualization) 5. In browser: - http://localhost/ shows the UI 6. ./server-down.sh (to stop the server when done) 7. On Windows, to completely stop the processes, you might have to run wsl --shutdown\nWhen modifying scripts in the /scripts folder, servers do not need to be restarted: - When modifying an existing script, simply re-run the script from the UI and the new version will be executed. - When adding or renaming scripts, refresh the browser page.\nWhen modifying pipelines in the /pipelines folder, servers do not need to be restarted: - In the pipeline editor, click save, paste the file to your file in the pipeline folder and run it from the “pipeline run” page. - When adding or renaming pipelines, refresh the browser page."
  },
  {
    "objectID": "README-user.html#running-the-servers-remotely",
    "href": "README-user.html#running-the-servers-remotely",
    "title": "BON in a Box Pipelines - User Documentation",
    "section": "",
    "text": "Use the ansible playbook instructions."
  },
  {
    "objectID": "README-user.html#running-a-script-or-pipeline",
    "href": "README-user.html#running-a-script-or-pipeline",
    "title": "BON in a Box Pipelines - User Documentation",
    "section": "",
    "text": "You have an instance of BON in a Box running, either locally or remotely, and you want to run your first script or pipeline.\nThere is one page to run scripts, and one to run pipelines. Select the script or pipelines from the dropdown and fill the form.\nThe form might ask you for a file. In order to provide a file that you own locally, upload or copy it to the userdata folder. You can then refer to it with a url as such: /userdata/myFile.shp, or /userdata/myFolder/myFile.shp if there are subfolders."
  },
  {
    "objectID": "README-user.html#scripts",
    "href": "README-user.html#scripts",
    "title": "BON in a Box Pipelines - User Documentation",
    "section": "",
    "text": "The scripts perform the actual work behind the scenes. They are located in /scripts folder\nCurrently supported : - R v4.3.1 - Julia v1.9.3 - Python3 v3.9.2 - sh\nScript lifecycle: 1. Script launched with output folder as a parameter. (In R, an outputFolder variable in the R session. In Julia, Shell and Python, the output folder is received as an argument.) 3. Script reads input.json to get execution parameters (ex. species, area, data source, etc.) 4. Script performs its task 5. Script generates output.json containing links to result files, or native values (number, string, etc.)\nSee empty R script for a minimal script lifecycle example.\n\n\nThe script description is in a .yml file next to the script. It is necessary for the script to be found and connected to other scripts in a pipeline.\nHere is an empty commented sample:\nscript: # script file with extension, such as \"myScript.py\".\nname: # short name, such as My Script\ndescription: # Targetted to those who will interpret pipeline results and edit pipelines.\nauthor: # 1 to many\n  - name: # Full name\n    email: # Optional, email address of the author. This will be publicly available.\n    identifier: # Optional, full URL of a unique digital identifier, such as an ORCID.\nlicense: # Optional. If unspecified, the project's MIT license will apply.\nexternal_link: # Optional, link to a separate project, github repo, etc.\ntimeout: # Optional, in minutes. By defaults steps time out after 1h to avoid hung process to consume resources. It can be made longer for heavy processes.\n\ninputs: # 0 to many\n  key: # replace the word \"key\" by a snake case identifier for this input\n    label: # Human-readable version of the name\n    description: # Targetted to those who will interpret pipeline results and edit pipelines.\n    type: # see below\n    example: # will also be used as default value, can be null\n\noutputs: # 1 to many\n  key:\n    label:\n    description:\n    type:\n    example: # optional, for documentation purpose only\n\nreferences: # 0 to many\n  - text: # plain text reference\n    doi: # link\nSee example\n\n\nEach input and output must declare a type, in lowercase. It can be a primitive or a file.\nThe following primitive types are accepted: | “type” attribute in the yaml | UI rendering | |——————————–|——————————| | boolean | Plain text | | float, float[] | Plain text | | int, int[] | Plain text | | options 2 | Plain text | | text, text[] | Plain text | | (any unknown type) | Plain text |\nAny MIME type is accepted. Here are a few common ones: | File type | MIME type to use in the yaml | UI rendering | | —————————- |——————————- |——————————| | CSV | text/csv | HTML table (partial content) | | GeoJSON | application/geo+json | Map | | GeoPackage | application/geopackage+sqlite3 | Link | | GeoTIFF 1 | image/tiff;application=geotiff | Map widget (leaflet) | | JPG | image/jpg | &lt;img&gt; tag | | Shapefile | application/dbf | Link | | Text | text/plain | Plain text | | TSV | text/tab-separated-values | HTML table (partial content) | | | (any unknown type) | Plain text or link |\nSearch the web to find the appropriate MIME type for your content. Here are a few references: - http://www.iana.org/assignments/media-types/media-types.xhtml - http://svn.apache.org/viewvc/httpd/httpd/trunk/docs/conf/mime.types?view=markup\n1 When used as an output, image/tiff;application=geotiff type allows an additionnal range attribute to be added with the min and max values that the tiff should hold. This will be used for display purposes.\nmap:\n  label: My map\n  description: Some map that shows bla bla...\n  type: image/tiff;application=geotiff\n  range: [0.1, 254]\n  example: https://example.com/mytiff.tif\n2 options type requires an additionnal options attribute to be added with the available options.\noptions_example:\n  label: Options example\n  description: The user has to select between a fixed number of text options. Also called select or enum. The script receives the selected option as text.\n  type: options\n  options:\n    - first option\n    - second option\n    - third option\n  example: third option\n\n\n\n\nThe syntax and structure of the script description file will be validated on push. To run the validation locally, run validate.sh\nThis validates that the syntax and structure are correct, but not that it’s content is correct. Hence, peer review of the scripts and the description files is mandatory before accepting a pull requests.\n\n\n\nThe output keys info, warning and error can be used to report problems in script execution. They do not need to be described in the outputs section of the description. They will be displayed specially in the UI.\nAny error message will halt the rest of the pipeline.\n\n\n\nScripts can install their own dependencies directly (install.packages in R, Pkg.add in Julia, etc). However, it will need to be reinstalled if the server is deployed on another computer or server.\nTo pre-compile the dependency in the image, add it to runners/r-dockerfile or runners/julia-dockerfile. When the pull request is merged to main, a new image will be available to docker compose pull with the added dependencies.\n\n\n\nWhen running a script, a folder is created for each given set of parameters. The same parameters result in the same folder, different parameters result in a different folder. The inputs for a given script are saved in an input.json file in this unique run folder.\nThe file contains the id of the parameters that were specified in the yaml script description, associated to the values for this run. Example:\n{\n    \"fc\": [\"L\", \"LQ\", \"LQHP\"],\n    \"method_select_params\": \"AUC\",\n    \"n_folds\": 2,\n    \"orientation_block\": \"lat_lon\",\n    \"partition_type\": \"block\",\n    \"predictors\": [\n        \"/output/data/loadFromStac/6af2ccfcd4b0ffe243ff01e3b7eccdc3/bio1_75548ca61981-01-01.tif\",\n        \"/output/data/loadFromStac/6af2ccfcd4b0ffe243ff01e3b7eccdc3/bio2_7333b3d111981-01-01.tif\"\n    ],\n    \"presence_background\": \"/output/SDM/setupDataSdm/edb9492031df9e063a5ec5c325bacdb1/presence_background.tsv\",\n    \"proj\": \"EPSG:6623\",\n    \"rm\": [0.5, 1.0, 2.0]\n}\nThe script reads and uses inputs from the input.json file. Example in R:\n## Receiving arguments from input.json.\n## outputFolder is already defined by server\nlibrary(\"rjson\")\ninput &lt;- fromJSON(file=file.path(outputFolder, \"input.json\"))\n\n## Can now be accessed from the map\nprint(input$predictors)\nThe script should perform appropriate parameter validation.\nNote that the inputs will be null if the user left the text box empty.\n\n\n\nThe output files generated by the script must be saved in the run folder. The script must also generate an output.json file in the same folder, that contains a map associating the output ids to their values. Example:\n{\n  \"sdm_pred\": \"/output/SDM/runMaxent/b5937ba69418b65cae7c6cfcfa78b5e8/sdm_pred.tif\",\n  \"sdm_runs\":[\n    \"/output/SDM/runMaxent/b5937ba69418b65cae7c6cfcfa78b5e8/sdm_runs_1.tif\",\n    \"/output/SDM/runMaxent/b5937ba69418b65cae7c6cfcfa78b5e8/sdm_runs_2.tif\"\n  ]\n}"
  },
  {
    "objectID": "README-user.html#pipelines",
    "href": "README-user.html#pipelines",
    "title": "BON in a Box Pipelines - User Documentation",
    "section": "",
    "text": "A pipeline is a collection of steps to acheive the desired processing. Each script becomes a pipeline step. \nPipelines also have inputs and outputs. In order to run, a pipeline needs to specify at least one output (rightmost red box in image above). Pipeline IO supports the same types and UI rendering as individual steps, since its inputs are directly fed to the steps, and outputs come from the step outputs.\nFor a general description of pipelines in software engineering, see Wikipedia.\n\n\nThe pipeline editor allows you to create pipelines by plugging steps together.\nThe left pane shows the available steps, the main section shows the canvas.\nOn the right side, a collapsible pane allows to edit the labels and descriptions of the pipeline inputs and outputs.\nTo add a step: drag and drop from the left pane to the canvas. Steps that are single scripts will display with a single border, while steps that are pipelines will display with a double border.\n\n\n\nimage\n\n\nTo connect steps: drag to connect an output and an input handle. Input handles are on the left, output handles are on the right.\nTo add a constant value: double-click on any input to add a constant value linked to this input. It is pre-filled with the example value.\nTo add an output: double-click on any step output to add a pipeline output linked to it, or drag and drop the red box from the left pane and link it manually.\nTo delete a step or a pipe: select it and press the Delete key on your keyboard.\nTo make an array out of single value outputs: if many outputs of the same type are connected to the same input, it will be received as an array by the script.\n\nA single value can also be combined with an array of the same type, to produce a single array.\n\nUser inputs: To provide inputs at runtime, simply leave them unconnected in the pipeline editor. They will be added to the sample input file when running the pipeline.\nIf an input is common to many step, a special user input node can be added to avoid duplication. First, link your nodes to a constant.\n\nThen, use the down arrow to pop the node’s menu. Choose “Convert to user input”.\n\nThe node will change as below, and the details will appear on the right pane, along with the other user inputs.\n\n\n\n\nAny input with no constant value assigned will be considered a pipeline input and user will have to fill the value.\nAdd an output node linked to a step output to specify that this output is an output of the pipeline. All other unmarked step outputs will still be available as intermediate results in the UI.\n\n\n\nimage\n\n\nPipeline inputs and outputs then appear in a collapsible pane on the right of the canvas, where their descriptions and labels can be edited.\n\nOnce edited, make sure to save your work before leaving the page.\n\n\n\nThe editor supports saving and loading on the server, unless explicitly disabled by host. This is done intuitively via the “Load from server” and “Save” buttons.\nIn the event that saving has been disabled on your server instance, the save button will display “Save to clipboard”. To save your modifications: 1. Click save: the content is copied to your clipboard. 2. Make sure you are up to date (e.g. git pull --rebase). 3. Remove all the content of the target file. 4. Paste content and save. 5. Commit and push on a branch using git. 6. To share your modifications, create a pull request for that branch through the github UI."
  },
  {
    "objectID": "ui/BonInABoxScriptService/docs/Info.html",
    "href": "ui/BonInABoxScriptService/docs/Info.html",
    "title": "BonInABoxScriptService.Info",
    "section": "",
    "text": "Name\nType\nDescription\nNotes\n\n\n\n\nscript\nString\n\n[optional]\n\n\nname\nString\n\n[optional]\n\n\ndescription\nString\n\n[optional]\n\n\nauthor\n[InfoAuthorInner]\n\n[optional]\n\n\nlicense\nString\n\n[optional]\n\n\nexternalLink\nString\n\n[optional]\n\n\ntimeout\nNumber\n\n[optional]\n\n\ninputs\n{String: InfoInputsValue}\n\n[optional]\n\n\noutputs\n{String: InfoOutputsValue}\n\n[optional]\n\n\nreferences\n[InfoReferencesInner]\n\n[optional]"
  },
  {
    "objectID": "ui/BonInABoxScriptService/docs/Info.html#properties",
    "href": "ui/BonInABoxScriptService/docs/Info.html#properties",
    "title": "BonInABoxScriptService.Info",
    "section": "",
    "text": "Name\nType\nDescription\nNotes\n\n\n\n\nscript\nString\n\n[optional]\n\n\nname\nString\n\n[optional]\n\n\ndescription\nString\n\n[optional]\n\n\nauthor\n[InfoAuthorInner]\n\n[optional]\n\n\nlicense\nString\n\n[optional]\n\n\nexternalLink\nString\n\n[optional]\n\n\ntimeout\nNumber\n\n[optional]\n\n\ninputs\n{String: InfoInputsValue}\n\n[optional]\n\n\noutputs\n{String: InfoOutputsValue}\n\n[optional]\n\n\nreferences\n[InfoReferencesInner]\n\n[optional]"
  },
  {
    "objectID": "ui/BonInABoxScriptService/docs/InfoInputsValue.html",
    "href": "ui/BonInABoxScriptService/docs/InfoInputsValue.html",
    "title": "BonInABoxScriptService.InfoInputsValue",
    "section": "",
    "text": "Name\nType\nDescription\nNotes\n\n\n\n\ndescription\nString\n\n[optional]\n\n\nlabel\nString\n\n[optional]\n\n\nweight\nNumber\nThe weight is used to sort inputs in the client UI.\n[optional]\n\n\ntype\nString\n\n[optional]\n\n\noptions\n[String]\n\n[optional]\n\n\nproperties\n[String]\n\n[optional]\n\n\nexample\nInfoInputsValueExample\n\n[optional]"
  },
  {
    "objectID": "ui/BonInABoxScriptService/docs/InfoInputsValue.html#properties",
    "href": "ui/BonInABoxScriptService/docs/InfoInputsValue.html#properties",
    "title": "BonInABoxScriptService.InfoInputsValue",
    "section": "",
    "text": "Name\nType\nDescription\nNotes\n\n\n\n\ndescription\nString\n\n[optional]\n\n\nlabel\nString\n\n[optional]\n\n\nweight\nNumber\nThe weight is used to sort inputs in the client UI.\n[optional]\n\n\ntype\nString\n\n[optional]\n\n\noptions\n[String]\n\n[optional]\n\n\nproperties\n[String]\n\n[optional]\n\n\nexample\nInfoInputsValueExample\n\n[optional]"
  },
  {
    "objectID": "ui/BonInABoxScriptService/docs/InfoInputsValueExampleOneOfInner.html",
    "href": "ui/BonInABoxScriptService/docs/InfoInputsValueExampleOneOfInner.html",
    "title": "BonInABoxScriptService.InfoInputsValueExampleOneOfInner",
    "section": "",
    "text": "Name\nType\nDescription\nNotes"
  },
  {
    "objectID": "ui/BonInABoxScriptService/docs/InfoInputsValueExampleOneOfInner.html#properties",
    "href": "ui/BonInABoxScriptService/docs/InfoInputsValueExampleOneOfInner.html#properties",
    "title": "BonInABoxScriptService.InfoInputsValueExampleOneOfInner",
    "section": "",
    "text": "Name\nType\nDescription\nNotes"
  },
  {
    "objectID": "ui/BonInABoxScriptService/docs/InfoOutputsValueExample.html",
    "href": "ui/BonInABoxScriptService/docs/InfoOutputsValueExample.html",
    "title": "BonInABoxScriptService.InfoOutputsValueExample",
    "section": "",
    "text": "Name\nType\nDescription\nNotes"
  },
  {
    "objectID": "ui/BonInABoxScriptService/docs/InfoOutputsValueExample.html#properties",
    "href": "ui/BonInABoxScriptService/docs/InfoOutputsValueExample.html#properties",
    "title": "BonInABoxScriptService.InfoOutputsValueExample",
    "section": "",
    "text": "Name\nType\nDescription\nNotes"
  },
  {
    "objectID": "how_to_install.html",
    "href": "how_to_install.html",
    "title": "How to Install",
    "section": "",
    "text": "If you wish to contribute your indicator or EBV code, please let us know at web@geobon.org.\nThe recommended method is to setup an instance of BON in a Box somewhere you can easily play with the script files, using the local or remote setup below. You can create a branch or fork to save your work. Make sure that the code is general, and will work when used with various parameters, such as in different regions around the globe. Once the integration of the new scripts or pipelines are complete, open a pull request to this repository. The pull request will be peer-reviewed before acceptation."
  },
  {
    "objectID": "how_to_install.html#contributing",
    "href": "how_to_install.html#contributing",
    "title": "How to Install",
    "section": "",
    "text": "If you wish to contribute your indicator or EBV code, please let us know at web@geobon.org.\nThe recommended method is to setup an instance of BON in a Box somewhere you can easily play with the script files, using the local or remote setup below. You can create a branch or fork to save your work. Make sure that the code is general, and will work when used with various parameters, such as in different regions around the globe. Once the integration of the new scripts or pipelines are complete, open a pull request to this repository. The pull request will be peer-reviewed before acceptation."
  },
  {
    "objectID": "how_to_install.html#running-the-servers-locally",
    "href": "how_to_install.html#running-the-servers-locally",
    "title": "How to Install",
    "section": "Running the servers locally",
    "text": "Running the servers locally\nPrerequisites :\n\nGit - A github account, with an SSH key registered. See Adding a new SSH key to your GitHub account.\nAt least 6 GB of free space (this includes the installation of Docker Desktop) - RAM requirements will depend on the scripts that you run.\nWindows:\n\nDocker Desktop - Note that it is not necessary to make an account\n\nA Linux shell (git bash, Bash through PowerShell, cygwin, etc.) necessary to run th .sh scripts in the instructions below.\nMac:\nDocker Desktop Note that it is not necessary to make an account\nMake sure docker is added to the path of your terminal. From a terminal, run command docker run hello-world. If there is an error message, see https://stackoverflow.com/a/71923962/3519951.\nIf you encounter error no matching manifest for linux/arm64/v8 in the manifest list entries, export DOCKER_DEFAULT_PLATFORM. See https://stackoverflow.com/a/76404045/3519951.\nLinux: Docker with Docker Compose installed. It is recommended to add your user to the docker group.\n\nTo run:\n\nClone repository (Windows users: do not clone the repo in a folder under OneDrive.) This can be done in terminal using the following code: git clone git@github.com:GEO-BON/bon-in-a-box-pipelines.git or in GitHub desktop.\nProvide the environment variables: - Open the newly cloned repository on your computer - Find the file called runner-sample.env - Duplicate the file and rename the copy to runner.env. - Fill the properties depending on what you intend to run. - Adjust any server option as you see fit.\nUsing a linux terminal (terminal on Mac or Git Bash), navigate to top-level folder.\nIn the linux terminal, type ./server-up.sh\n\nMake sure you have docker open and running on your computer.\nThe first execution will be long, in order to download the micro-services. The next ones will be shorter or immediate, depending on the changes.\nNetwork problems may cause the process to fail. First try running the command again. Intermediate states are saved so not everything will be redone even when there is a failure.\nWindows users may need to turn on virtualization and other tools for Docker Desktop to work and update wsl (“wsl –update”, see https://docs.docker.com/desktop/troubleshoot/topics/#virtualization. Access to the BIOS may be required to enable virtualization)\n\nType http://localhost/ to open BON in a Box\nRun ./server-down.sh in a terminal to stop the server when done\nOn Windows, to completely stop the processes, you might have to run wsl --shutdown\n\nWhen modifying scripts in the /scripts folder, servers do not need to be restarted: - When modifying an existing script, simply re-run the script from the UI and the new version will be executed. - When adding or renaming scripts, refresh the browser page.\nWhen modifying pipelines in the /pipelines folder, servers do not need to be restarted: - In the pipeline editor, click save, paste the file to your file in the pipeline folder and run it from the “pipeline run” page. - When adding or renaming pipelines, refresh the browser page."
  },
  {
    "objectID": "how_to_install.html#running-the-servers-remotely",
    "href": "how_to_install.html#running-the-servers-remotely",
    "title": "How to Install",
    "section": "Running the servers remotely",
    "text": "Running the servers remotely\nUse the ansible playbook instructions."
  },
  {
    "objectID": "how_to_install.html#running-a-script-or-pipeline",
    "href": "how_to_install.html#running-a-script-or-pipeline",
    "title": "How to Install",
    "section": "Running a script or pipeline",
    "text": "Running a script or pipeline\nYou have an instance of BON in a Box running, either locally or remotely, and you want to run your first script or pipeline.\nThere is one page to run scripts, and one to run pipelines. Select the script or pipelines from the dropdown and fill the form.\nThe form might ask you for a file. In order to provide a file that you own locally, upload or copy it to the userdata folder. You can then refer to it with a url as such: /userdata/myFile.shp, or /userdata/myFolder/myFile.shp if there are subfolders."
  },
  {
    "objectID": "how_to_install.html#scripts",
    "href": "how_to_install.html#scripts",
    "title": "How to Install",
    "section": "Scripts",
    "text": "Scripts\nThe scripts perform the actual work behind the scenes. They are located in /scripts folder\nCurrently supported : - R v4.3.1 - Julia v1.9.3 - Python3 v3.9.2 - sh\nScript lifecycle:\n\nScript launched with output folder as a parameter. (In R, an outputFolder variable in the R session. In Julia, Shell and Python, the output folder is received as an argument.)\nScript reads input.json to get execution parameters (ex. species, area, data source, etc.)\nScript performs its task\nScript generates output.json containing links to result files, or native values (number, string, etc.)\n\nSee empty R script for a minimal script lifecycle example.\n\nDescribing a script\nThe script description is in a .yml file next to the script. It is necessary for the script to be found and connected to other scripts in a pipeline.\nHere is an empty commented sample:\nscript: # script file with extension, such as \"myScript.py\".\nname: # short name, such as My Script\ndescription: # Targetted to those who will interpret pipeline results and edit pipelines.\nauthor: # 1 to many\n  - name: # Full name\n    email: # Optional, email address of the author. This will be publicly available.\n    identifier: # Optional, full URL of a unique digital identifier, such as an ORCID.\nlicense: # Optional. If unspecified, the project's MIT license will apply.\nexternal_link: # Optional, link to a separate project, github repo, etc.\ntimeout: # Optional, in minutes. By defaults steps time out after 1h to avoid hung process to consume resources. It can be made longer for heavy processes.\n\ninputs: # 0 to many\n  key: # replace the word \"key\" by a snake case identifier for this input\n    label: # Human-readable version of the name\n    description: # Targetted to those who will interpret pipeline results and edit pipelines.\n    type: # see below\n    example: # will also be used as default value, can be null\n\noutputs: # 1 to many\n  key:\n    label:\n    description:\n    type:\n    example: # optional, for documentation purpose only\n\nreferences: # 0 to many\n  - text: # plain text reference\n    doi: # link\nSee example\n\nInput and output types\nEach input and output must declare a type, in lowercase. It can be a primitive or a file.\nThe following primitive types are accepted:\n\n\n\n“Type” attribute in the yaml\nIU rendering\n\n\n\n\nboolean\nPlain text\n\n\nfloat, float[]\nPlain text\n\n\nint, int[]\nPlain text\n\n\noptions (INSERT FOOTNOTE)\nPlain text\n\n\ntext, text[]\nPlain text\n\n\n(any unknown type)\nPlain text\n\n\n\nAny MIME type is accepted. Here are a few common ones:\n\n\n\n\n\n\n\n\nFile Type\nMIME type to use in the yaml\nUI rendering\n\n\n\n\nCSV\ntext/csv\nHTML table (partial content)\n\n\nGeoJSON\napplication/geo+json\nMap\n\n\nGeoTIFF (INSERT FOOTNOTE)\napplication/geopackage+sqlite3\nLink\n\n\nJPG\nimage/tiff;application=geotiff\nMap widget (leaflet)\n\n\nJPG\nimage/jpg\n tag\n\n\nShapefile\napplication/dbf\nLink\n\n\nText\ntext/plain\nPlain text\n\n\nTSV\ntext/tab-separated-values\nHTML table (partial content)\n\n\n\n(any unknown type)\nPlain text or link\n\n\n\nSearch the web to find the appropriate MIME type for your content. Here are a few references: - http://www.iana.org/assignments/media-types/media-types.xhtml - http://svn.apache.org/viewvc/httpd/httpd/trunk/docs/conf/mime.types?view=markup\nWhen used as an output, image/tiff;application=geotiff type allows an additionnal range attribute to be added with the min and max values that the tiff should hold. This will be used for display purposes.\nmap:\n  label: My map\n  description: Some map that shows bla bla...\n  type: image/tiff;application=geotiff\n  range: [0.1, 254]\n  example: https://example.com/mytiff.tif\noptions type requires an additionnal options attribute to be added with the available options.\noptions_example:\n  label: Options example\n  description: The user has to select between a fixed number of text options. Also called select or enum. The script receives the selected option as text.\n  type: options\n  options:\n    - first option\n    - second option\n    - third option\n  example: third option\n\n\n\nScript validation\nThe syntax and structure of the script description file will be validated on push. To run the validation locally, run validate.sh\nThis validates that the syntax and structure are correct, but not that it’s content is correct. Hence, peer review of the scripts and the description files is mandatory before accepting a pull requests.\n\n\nReporting problems\nThe output keys info, warning and error can be used to report problems in script execution. They do not need to be described in the outputs section of the description. They will be displayed specially in the UI.\nAny error message will halt the rest of the pipeline.\n\n\nScript dependencies\nScripts can install their own dependencies directly (install.packages in R, Pkg.add in Julia, etc). However, it will need to be reinstalled if the server is deployed on another computer or server.\nTo pre-compile the dependency in the image, add it to runners/r-dockerfile or runners/julia-dockerfile. When the pull request is merged to main, a new image will be available to docker compose pull with the added dependencies.\n\n\nReceiving inputs\nWhen running a script, a folder is created for each given set of parameters. The same parameters result in the same folder, different parameters result in a different folder. The inputs for a given script are saved in an input.json file in this unique run folder.\nThe file contains the id of the parameters that were specified in the yaml script description, associated to the values for this run. Example:\n{\n    \"fc\": [\"L\", \"LQ\", \"LQHP\"],\n    \"method_select_params\": \"AUC\",\n    \"n_folds\": 2,\n    \"orientation_block\": \"lat_lon\",\n    \"partition_type\": \"block\",\n    \"predictors\": [\n        \"/output/data/loadFromStac/6af2ccfcd4b0ffe243ff01e3b7eccdc3/bio1_75548ca61981-01-01.tif\",\n        \"/output/data/loadFromStac/6af2ccfcd4b0ffe243ff01e3b7eccdc3/bio2_7333b3d111981-01-01.tif\"\n    ],\n    \"presence_background\": \"/output/SDM/setupDataSdm/edb9492031df9e063a5ec5c325bacdb1/presence_background.tsv\",\n    \"proj\": \"EPSG:6623\",\n    \"rm\": [0.5, 1.0, 2.0]\n}\nThe script reads and uses inputs from the input.json file. Example in R:\n## Receiving arguments from input.json.\n## outputFolder is already defined by server\nlibrary(\"rjson\")\ninput &lt;- fromJSON(file=file.path(outputFolder, \"input.json\"))\n\n## Can now be accessed from the map\nprint(input$predictors)\nThe script should perform appropriate parameter validation.\nNote that the inputs will be null if the user left the text box empty.\n\n\nGenerating outputs\nThe output files generated by the script must be saved in the run folder. The script must also generate an output.json file in the same folder, that contains a map associating the output ids to their values. Example:\n{\n  \"sdm_pred\": \"/output/SDM/runMaxent/b5937ba69418b65cae7c6cfcfa78b5e8/sdm_pred.tif\",\n  \"sdm_runs\":[\n    \"/output/SDM/runMaxent/b5937ba69418b65cae7c6cfcfa78b5e8/sdm_runs_1.tif\",\n    \"/output/SDM/runMaxent/b5937ba69418b65cae7c6cfcfa78b5e8/sdm_runs_2.tif\"\n  ]\n}"
  },
  {
    "objectID": "how_to_install.html#pipelines",
    "href": "how_to_install.html#pipelines",
    "title": "How to Install",
    "section": "Pipelines",
    "text": "Pipelines\nA pipeline is a collection of steps to acheive the desired processing. Each script becomes a pipeline step. \nPipelines also have inputs and outputs. In order to run, a pipeline needs to specify at least one output (rightmost red box in image above). Pipeline IO supports the same types and UI rendering as individual steps, since its inputs are directly fed to the steps, and outputs come from the step outputs.\nFor a general description of pipelines in software engineering, see Wikipedia.\n\nPipeline editor\nThe pipeline editor allows you to create pipelines by plugging steps together.\nThe left pane shows the available steps, the main section shows the canvas.\nOn the right side, a collapsible pane allows to edit the labels and descriptions of the pipeline inputs and outputs.\nTo add a step: drag and drop from the left pane to the canvas. Steps that are single scripts will display with a single border, while steps that are pipelines will display with a double border.\n\n\n\nimage\n\n\nTo connect steps: drag to connect an output and an input handle. Input handles are on the left, output handles are on the right.\nTo add a constant value: double-click on any input to add a constant value linked to this input. It is pre-filled with the example value.\nTo add an output: double-click on any step output to add a pipeline output linked to it, or drag and drop the red box from the left pane and link it manually.\nTo delete a step or a pipe: select it and press the Delete key on your keyboard.\nTo make an array out of single value outputs: if many outputs of the same type are connected to the same input, it will be received as an array by the script.\n\nA single value can also be combined with an array of the same type, to produce a single array.\n\nUser inputs: To provide inputs at runtime, simply leave them unconnected in the pipeline editor. They will be added to the sample input file when running the pipeline.\nIf an input is common to many step, a special user input node can be added to avoid duplication. First, link your nodes to a constant.\n\nThen, use the down arrow to pop the node’s menu. Choose “Convert to user input”.\n\nThe node will change as below, and the details will appear on the right pane, along with the other user inputs.\n\n\n\nPipeline inputs and outputs\nAny input with no constant value assigned will be considered a pipeline input and user will have to fill the value.\nAdd an output node linked to a step output to specify that this output is an output of the pipeline. All other unmarked step outputs will still be available as intermediate results in the UI.\n\n\n\nimage\n\n\nPipeline inputs and outputs then appear in a collapsible pane on the right of the canvas, where their descriptions and labels can be edited.\n\nOnce edited, make sure to save your work before leaving the page.\n\n\nSaving and loading\nThe editor supports saving and loading on the server, unless explicitly disabled by host. This is done intuitively via the “Load from server” and “Save” buttons.\nIn the event that saving has been disabled on your server instance, the save button will display “Save to clipboard”. To save your modifications: 1. Click save: the content is copied to your clipboard. 2. Make sure you are up to date (e.g. git pull --rebase). 3. Remove all the content of the target file. 4. Paste content and save. 5. Commit and push on a branch using git. 6. To share your modifications, create a pull request for that branch through the github UI."
  },
  {
    "objectID": "how_to_contribute.html",
    "href": "how_to_contribute.html",
    "title": "How to Contribute",
    "section": "",
    "text": "This is how you contribute to BON in a Box!"
  }
]